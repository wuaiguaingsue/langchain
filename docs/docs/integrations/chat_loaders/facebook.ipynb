{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bd269b",
   "metadata": {},
   "source": [
    "# Facebook Messenger\n",
    "\n",
    "本笔记本展示如何以可用于微调的格式加载来自Facebook的数据。整体步骤如下：\n",
    "\n",
    "1. 将您的消息数据下载到磁盘。\n",
    "2. 创建聊天加载器并调用`loader.load()`（或`loader.lazy_load()`）执行转换。\n",
    "3. 可以选择使用`merge_chat_runs`来合并来自同一发送者的连续消息，和/或使用`map_ai_messages`将指定发送者的消息转换为\"AIMessage\"类。完成此操作后，调用`convert_messages_for_finetuning`准备用于微调的数据。\n",
    "\n",
    "\n",
    "完成这些步骤后，您可以微调您的模型。为此，您需要完成以下步骤：\n",
    "\n",
    "4. 将您的消息上传到OpenAI并运行微调作业。\n",
    "6. 在您的LangChain应用中使用生成的模型！\n",
    "\n",
    "\n",
    "让我们开始。\n",
    "\n",
    "\n",
    "## 1. 下载数据\n",
    "\n",
    "要下载您自己的Messenger数据，请按照[此处](https://www.zapptales.com/en/download-facebook-messenger-chat-history-how-to/)的说明进行操作。重要提示 - 确保以JSON格式下载（而非HTML）。\n",
    "\n",
    "我们正在[此Google云端硬盘链接](https://drive.google.com/file/d/1rh1s1o2i7B-Sk1v9o8KNgivLVGwJ-osV/view?usp=sharing)上托管一个示例数据，我们将在本教程中使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647f2158-a42e-4634-b283-b8492caf542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File file.zip downloaded.\n",
      "File file.zip has been unzipped.\n"
     ]
    }
   ],
   "source": [
    "# This uses some example data\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_and_unzip(url: str, output_path: str = \"file.zip\") -> None:\n",
    "    file_id = url.split(\"/\")[-2]\n",
    "    download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
    "\n",
    "    response = requests.get(download_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to download the file.\")\n",
    "        return\n",
    "\n",
    "    with open(output_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "        print(f\"File {output_path} downloaded.\")\n",
    "\n",
    "    with zipfile.ZipFile(output_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "        print(f\"File {output_path} has been unzipped.\")\n",
    "\n",
    "\n",
    "# URL of the file to download\n",
    "url = (\n",
    "    \"https://drive.google.com/file/d/1rh1s1o2i7B-Sk1v9o8KNgivLVGwJ-osV/view?usp=sharing\"\n",
    ")\n",
    "\n",
    "# Download and unzip\n",
    "download_and_unzip(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef8bb1-fc28-453c-835a-94a552f05a91",
   "metadata": {},
   "source": [
    "## 2. 创建聊天加载器\n",
    "\n",
    "我们有2种不同的`FacebookMessengerChatLoader`类，一种用于整个聊天目录，另一种用于加载单个文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0869bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./hogwarts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0460bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_loaders.facebook_messenger import (\n",
    "    FolderFacebookMessengerChatLoader,\n",
    "    SingleFileFacebookMessengerChatLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f61ee277",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SingleFileFacebookMessengerChatLoader(\n",
    "    path=\"./hogwarts/inbox/HermioneGranger/messages_Hermione_Granger.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec466ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hi Hermione! How's your summer going so far?\", additional_kwargs={'sender': 'Harry Potter'}),\n",
       " HumanMessage(content=\"Harry! Lovely to hear from you. My summer is going well, though I do miss everyone. I'm spending most of my time going through my books and researching fascinating new topics. How about you?\", additional_kwargs={'sender': 'Hermione Granger'}),\n",
       " HumanMessage(content=\"I miss you all too. The Dursleys are being their usual unpleasant selves but I'm getting by. At least I can practice some spells in my room without them knowing. Let me know if you find anything good in your researching!\", additional_kwargs={'sender': 'Harry Potter'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_session = loader.load()[0]\n",
    "chat_session[\"messages\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3ee473",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = FolderFacebookMessengerChatLoader(\n",
    "    path=\"./hogwarts\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f41e122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_sessions = loader.load()\n",
    "len(chat_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aa3580-adc1-4b48-9bba-0e8e8d9f44ce",
   "metadata": {},
   "source": [
    "## 3. 准备微调\n",
    "\n",
    "调用`load()`返回我们能够提取的所有聊天消息作为人类消息。与聊天机器人的对话通常遵循比真实对话更严格的交替对话模式。\n",
    "\n",
    "您可以选择合并消息\"序列\"（来自同一发送者的连续消息）并选择一个发送者来代表\"AI\"。经过微调的LLM将学习生成这些AI消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a78030d-b757-4bbe-8a6c-841056f46df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_loaders.utils import (\n",
    "    map_ai_messages,\n",
    "    merge_chat_runs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff35b028-78bf-4c5b-9ec6-939fe67de7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sessions = merge_chat_runs(chat_sessions)\n",
    "alternating_sessions = list(map_ai_messages(merged_sessions, \"Harry Potter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b11906e-a496-4d01-9f0d-1938c14147bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Professor Snape, I was hoping I could speak with you for a moment about something that's been concerning me lately.\", additional_kwargs={'sender': 'Harry Potter'}),\n",
       " HumanMessage(content=\"What is it, Potter? I'm quite busy at the moment.\", additional_kwargs={'sender': 'Severus Snape'}),\n",
       " AIMessage(content=\"I apologize for the interruption, sir. I'll be brief. I've noticed some strange activity around the school grounds at night. I saw a cloaked figure lurking near the Forbidden Forest last night. I'm worried someone may be plotting something sinister.\", additional_kwargs={'sender': 'Harry Potter'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now all of Harry Potter's messages will take the AI message class\n",
    "# which maps to the 'assistant' role in OpenAI's training format\n",
    "alternating_sessions[0][\"messages\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d985478d-062e-47b9-ae9a-102f59be07c0",
   "metadata": {},
   "source": [
    "#### 现在我们可以转换为OpenAI格式的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21372331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.adapters.openai import convert_messages_for_finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c5ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 9 dialogues for training\n"
     ]
    }
   ],
   "source": [
    "training_data = convert_messages_for_finetuning(alternating_sessions)\n",
    "print(f\"Prepared {len(training_data)} dialogues for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfcbd181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'assistant',\n",
       "  'content': \"Professor Snape, I was hoping I could speak with you for a moment about something that's been concerning me lately.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"What is it, Potter? I'm quite busy at the moment.\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"I apologize for the interruption, sir. I'll be brief. I've noticed some strange activity around the school grounds at night. I saw a cloaked figure lurking near the Forbidden Forest last night. I'm worried someone may be plotting something sinister.\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a9fd64-4f9f-42d3-b5dc-2a340e51e9e7",
   "metadata": {},
   "source": [
    "OpenAI目前要求微调作业至少有10个训练示例，尽管他们建议大多数任务使用50-100个。由于我们只有9个聊天会话，我们可以将它们细分（可选择一些重叠部分），使每个训练示例由整个对话的一部分组成。\n",
    "\n",
    "Facebook聊天会话（每人1个）通常跨越多天和多次对话，\n",
    "因此长距离依赖关系可能不是那么重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13cd290a-b1e9-4686-bb5e-d99de8b8612b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our chat is alternating, we will make each datapoint a group of 8 messages,\n",
    "# with 2 messages overlapping\n",
    "chunk_size = 8\n",
    "overlap = 2\n",
    "\n",
    "training_examples = [\n",
    "    conversation_messages[i : i + chunk_size]\n",
    "    for conversation_messages in training_data\n",
    "    for i in range(0, len(conversation_messages) - chunk_size + 1, chunk_size - overlap)\n",
    "]\n",
    "\n",
    "len(training_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8baf41-ff07-4492-96bd-b2472ee7cef9",
   "metadata": {},
   "source": [
    "## 4. 微调模型\n",
    "\n",
    "是时候微调模型了。确保您已安装`openai`\n",
    "并已正确设置您的`OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ce3f63-3c80-44b2-9060-534ad74e16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab9e28eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File file-ULumAXLEFw3vB6bb9uy6DNVC ready after 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from io import BytesIO\n",
    "\n",
    "import openai\n",
    "\n",
    "# We will write the jsonl file in memory\n",
    "my_file = BytesIO()\n",
    "for m in training_examples:\n",
    "    my_file.write((json.dumps({\"messages\": m}) + \"\\n\").encode(\"utf-8\"))\n",
    "\n",
    "my_file.seek(0)\n",
    "training_file = openai.files.create(file=my_file, purpose=\"fine-tune\")\n",
    "\n",
    "# OpenAI audits each training file for compliance reasons.\n",
    "# This make take a few minutes\n",
    "status = openai.files.retrieve(training_file.id).status\n",
    "start_time = time.time()\n",
    "while status != \"processed\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    status = openai.files.retrieve(training_file.id).status\n",
    "print(f\"File {training_file.id} ready after {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759a7f51-fde9-4b75-aaa9-e600e6537bd1",
   "metadata": {},
   "source": [
    "文件准备好后，是时候启动训练作业了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f451425",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = openai.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b23ef-5e14-42a9-bafb-44220ec6960b",
   "metadata": {},
   "source": [
    "在您的模型准备期间，不妨喝杯茶。这可能需要一些时间！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bac1637a-c087-4523-ade1-c47f9bf4c6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status=[running]... 874.29s. 56.93s\r"
     ]
    }
   ],
   "source": [
    "status = openai.fine_tuning.jobs.retrieve(job.id).status\n",
    "start_time = time.time()\n",
    "while status != \"succeeded\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    job = openai.fine_tuning.jobs.retrieve(job.id)\n",
    "    status = job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "535895e1-bc69-40e5-82ed-e24ed2baeeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-3.5-turbo-0613:personal::8QnAzWMr\n"
     ]
    }
   ],
   "source": [
    "print(job.fine_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ff73b-f9e9-49ce-ba45-401811e57946",
   "metadata": {},
   "source": [
    "## 5. 在LangChain中使用\n",
    "\n",
    "您可以直接在`ChatOpenAI`模型类中使用生成的模型ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3925d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=job.fine_tuned_model,\n",
    "    temperature=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7190cf2e-ab34-4ceb-bdad-45f24f069c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f02057e9-f914-40b1-9c9d-9432ff594b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm taking Charms, Defense Against the Dark Arts, Herbology, Potions, Transfiguration, and Ancient Runes. How about you?"
     ]
    }
   ],
   "source": [
    "for tok in chain.stream({\"input\": \"What classes are you taking?\"}):\n",
    "    print(tok, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
