{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argilla\n",
    "\n",
    ">[Argilla](https://argilla.io/) 是一个用于LLM的开源数据策划平台。\n",
    "> 使用Argilla，每个人都可以通过更快的数据策划构建强大的语言模型，\n",
    "> 同时利用人类和机器反馈。我们为MLOps周期中的每个步骤提供支持，\n",
    "> 从数据标注到模型监控。\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/integrations/callbacks/argilla.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"在Colab中打开\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本指南中，我们将演示如何使用`ArgillaCallbackHandler`跟踪LLM的输入和响应，以在Argilla中生成数据集。\n",
    "\n",
    "跟踪LLM的输入和输出以生成未来微调的数据集非常有用。当你使用LLM为特定任务生成数据时，如问答、摘要或翻译，这尤其有用。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 安装和设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai argilla"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取API凭证\n",
    "\n",
    "要获取Argilla API凭证，请按照以下步骤操作：\n",
    "\n",
    "1. 进入Argilla用户界面。\n",
    "2. 点击您的个人头像并前往\"我的设置\"。\n",
    "3. 然后复制API密钥。\n",
    "\n",
    "在Argilla中，API URL将与Argilla用户界面的URL相同。\n",
    "\n",
    "要获取OpenAI API凭证，请访问 https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ARGILLA_API_URL\"] = \"...\"\n",
    "os.environ[\"ARGILLA_API_KEY\"] = \"...\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置Argilla\n",
    "\n",
    "要使用`ArgillaCallbackHandler`，我们需要在Argilla中创建一个新的`FeedbackDataset`来跟踪LLM实验。请使用以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argilla as rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import parse as parse_version\n",
    "\n",
    "if parse_version(rg.__version__) < parse_version(\"1.8.0\"):\n",
    "    raise RuntimeError(\n",
    "        \"`FeedbackDataset`仅在Argilla v1.8.0或更高版本中可用，请\"\n",
    "        \"通过`pip install argilla --upgrade`升级`argilla`。\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rg.FeedbackDataset(\n",
    "    fields=[\n",
    "        rg.TextField(name=\"prompt\"),\n",
    "        rg.TextField(name=\"response\"),\n",
    "    ],\n",
    "    questions=[\n",
    "        rg.RatingQuestion(\n",
    "            name=\"response-rating\",\n",
    "            description=\"您如何评价响应的质量？\",\n",
    "            values=[1, 2, 3, 4, 5],\n",
    "            required=True,\n",
    "        ),\n",
    "        rg.TextQuestion(\n",
    "            name=\"response-feedback\",\n",
    "            description=\"您对响应有什么反馈？\",\n",
    "            required=False,\n",
    "        ),\n",
    "    ],\n",
    "    guidelines=\"您将被要求评价响应的质量并提供反馈。\",\n",
    ")\n",
    "\n",
    "rg.init(\n",
    "    api_url=os.environ[\"ARGILLA_API_URL\"],\n",
    "    api_key=os.environ[\"ARGILLA_API_KEY\"],\n",
    ")\n",
    "\n",
    "dataset.push_to_argilla(\"langchain-dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 📌 注意：目前，`FeedbackDataset.fields`仅支持提示-响应对，因此`ArgillaCallbackHandler`将只跟踪提示（即LLM输入）和响应（即LLM输出）。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跟踪"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要使用`ArgillaCallbackHandler`，您可以使用以下代码，或者复现以下部分中呈现的示例之一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks.argilla_callback import ArgillaCallbackHandler\n",
    "\n",
    "argilla_callback = ArgillaCallbackHandler(\n",
    "    dataset_name=\"langchain-dataset\",\n",
    "    api_url=os.environ[\"ARGILLA_API_URL\"],\n",
    "    api_key=os.environ[\"ARGILLA_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 场景1：跟踪LLM\n",
    "\n",
    "首先，让我们多次运行单个LLM，并在Argilla中捕获生成的提示-响应对。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nQ: What did the fish say when he hit the wall? \\nA: Dam.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe Moon \\n\\nThe moon is high in the midnight sky,\\nSparkling like a star above.\\nThe night so peaceful, so serene,\\nFilling up the air with love.\\n\\nEver changing and renewing,\\nA never-ending light of grace.\\nThe moon remains a constant view,\\nA reminder of life’s gentle pace.\\n\\nThrough time and space it guides us on,\\nA never-fading beacon of hope.\\nThe moon shines down on us all,\\nAs it continues to rise and elope.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ. What did one magnet say to the other magnet?\\nA. \"I find you very attractive!\"', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\nThe world is charged with the grandeur of God.\\nIt will flame out, like shining from shook foil;\\nIt gathers to a greatness, like the ooze of oil\\nCrushed. Why do men then now not reck his rod?\\n\\nGenerations have trod, have trod, have trod;\\nAnd all is seared with trade; bleared, smeared with toil;\\nAnd wears man's smudge and shares man's smell: the soil\\nIs bare now, nor can foot feel, being shod.\\n\\nAnd for all this, nature is never spent;\\nThere lives the dearest freshness deep down things;\\nAnd though the last lights off the black West went\\nOh, morning, at the brown brink eastward, springs —\\n\\nBecause the Holy Ghost over the bent\\nWorld broods with warm breast and with ah! bright wings.\\n\\n~Gerard Manley Hopkins\", generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nQ: What did one ocean say to the other ocean?\\nA: Nothing, they just waved.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text=\"\\n\\nA poem for you\\n\\nOn a field of green\\n\\nThe sky so blue\\n\\nA gentle breeze, the sun above\\n\\nA beautiful world, for us to love\\n\\nLife is a journey, full of surprise\\n\\nFull of joy and full of surprise\\n\\nBe brave and take small steps\\n\\nThe future will be revealed with depth\\n\\nIn the morning, when dawn arrives\\n\\nA fresh start, no reason to hide\\n\\nSomewhere down the road, there's a heart that beats\\n\\nBelieve in yourself, you'll always succeed.\", generation_info={'finish_reason': 'stop', 'logprobs': None})]], llm_output={'token_usage': {'completion_tokens': 504, 'total_tokens': 528, 'prompt_tokens': 24}, 'model_name': 'text-davinci-003'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.callbacks.stdout import StdOutCallbackHandler\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "argilla_callback = ArgillaCallbackHandler(\n",
    "    dataset_name=\"langchain-dataset\",\n",
    "    api_url=os.environ[\"ARGILLA_API_URL\"],\n",
    "    api_key=os.environ[\"ARGILLA_API_KEY\"],\n",
    ")\n",
    "callbacks = [StdOutCallbackHandler(), argilla_callback]\n",
    "\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks)\n",
    "llm.generate([\"讲个笑话\", \"给我写首诗\"] * 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![带有LangChain LLM输入-响应的Argilla界面](https://docs.argilla.io/en/latest/_images/llm.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 场景2：在链中跟踪LLM\n",
    "\n",
    "然后我们可以使用提示模板创建一个链，然后在Argilla中跟踪初始提示和最终响应。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a playwright. Given the title of play, it is your job to write a synopsis for that title.\n",
      "Title: Documentary about Bigfoot in Paris\n",
      "Playwright: This is a synopsis for the above play:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': \"\\n\\nDocumentary about Bigfoot in Paris focuses on the story of a documentary filmmaker and their search for evidence of the legendary Bigfoot creature in the city of Paris. The play follows the filmmaker as they explore the city, meeting people from all walks of life who have had encounters with the mysterious creature. Through their conversations, the filmmaker unravels the story of Bigfoot and finds out the truth about the creature's presence in Paris. As the story progresses, the filmmaker learns more and more about the mysterious creature, as well as the different perspectives of the people living in the city, and what they think of the creature. In the end, the filmmaker's findings lead them to some surprising and heartwarming conclusions about the creature's existence and the importance it holds in the lives of the people in Paris.\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.callbacks.stdout import StdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "argilla_callback = ArgillaCallbackHandler(\n",
    "    dataset_name=\"langchain-dataset\",\n",
    "    api_url=os.environ[\"ARGILLA_API_URL\"],\n",
    "    api_key=os.environ[\"ARGILLA_API_KEY\"],\n",
    ")\n",
    "callbacks = [StdOutCallbackHandler(), argilla_callback]\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks)\n",
    "\n",
    "template = \"\"\"你是一名剧作家。给定剧本标题，你的工作是为该标题写一个剧情概要。\n",
    "标题：{title}\n",
    "剧作家：这是上述剧本的概要：\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"title\"], template=template)\n",
    "synopsis_chain = LLMChain(llm=llm, prompt=prompt_template, callbacks=callbacks)\n",
    "\n",
    "test_prompts = [{\"title\": \"巴黎大脚怪纪录片\"}]\n",
    "synopsis_chain.apply(test_prompts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![带有LangChain Chain输入-响应的Argilla界面](https://docs.argilla.io/en/latest/_images/chain.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 场景3：使用带工具的Agent\n",
    "\n",
    "最后，作为一个更高级的工作流程，您可以创建一个使用某些工具的代理。`ArgillaCallbackHandler`将跟踪输入和输出，但不跟踪中间步骤/思考过程，因此给定一个提示，我们记录原始提示和对该提示的最终响应。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 注意，对于这个场景，我们将使用Google搜索API（Serp API），所以您需要同时安装`google-search-results`（通过`pip install google-search-results`），并设置Serp API密钥为`os.environ[\"SERPAPI_API_KEY\"] = \"...\"`（可以在https://serpapi.com/dashboard找到），否则下面的示例将无法工作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to answer a historical question\n",
      "Action: Search\n",
      "Action Input: \"who was the first president of the United States of America\" \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mGeorge Washington\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m George Washington was the first president\n",
      "Final Answer: George Washington was the first president of the United States of America.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'George Washington was the first president of the United States of America.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain_core.callbacks.stdout import StdOutCallbackHandler\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "argilla_callback = ArgillaCallbackHandler(\n",
    "    dataset_name=\"langchain-dataset\",\n",
    "    api_url=os.environ[\"ARGILLA_API_URL\"],\n",
    "    api_key=os.environ[\"ARGILLA_API_KEY\"],\n",
    ")\n",
    "callbacks = [StdOutCallbackHandler(), argilla_callback]\n",
    "llm = OpenAI(temperature=0.9, callbacks=callbacks)\n",
    "\n",
    "tools = load_tools([\"serpapi\"], llm=llm, callbacks=callbacks)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "agent.run(\"美国的第一任总统是谁？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![带有LangChain Agent输入-响应的Argilla界面](https://docs.argilla.io/en/latest/_images/agent.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a53ebf4a859167383b364e7e7521d0add3c2dbbdecce4edf676e8c4634ff3fbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
