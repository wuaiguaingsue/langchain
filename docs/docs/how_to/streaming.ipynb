{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0bdb3b97-4989-4237-b43b-5943dbbd8302",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "keywords: [stream]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d49db-04d3-4399-bfe1-09f82bbe6015",
   "metadata": {},
   "source": [
    "# 如何流式运行 Runnables\n",
    "\n",
    ":::info 前置条件\n",
    "\n",
    "本指南假设您已熟悉以下概念：\n",
    "- [聊天模型](/docs/concepts/chat_models)\n",
    "- [LangChain 表达式语言](/docs/concepts/lcel)\n",
    "- [输出解析器](/docs/concepts/output_parsers)\n",
    "\n",
    ":::\n",
    "\n",
    "流式传输对于使基于 LLM 的应用程序对终端用户感觉响应迅速至关重要。\n",
    "\n",
    "重要的 LangChain 原语（如 [聊天模型](/docs/concepts/chat_models)、[输出解析器](/docs/concepts/output_parsers)、[提示](/docs/concepts/prompt_templates)、[检索器](/docs/concepts/retrievers) 和 [代理](/docs/concepts/agents)）实现了 LangChain 的 [Runnable 接口](/docs/concepts/runnables)。\n",
    "\n",
    "此接口提供了两种流式传输内容的通用方法：\n",
    "\n",
    "1. 同步 `stream` 和异步 `astream`：一种流式传输的**默认实现**，用于从链中流式传输**最终输出**。\n",
    "2. 异步 `astream_events` 和异步 `astream_log`：这些方法提供了一种流式传输链中**中间步骤**和**最终输出**的方式。\n",
    "\n",
    "让我们来看看这两种方法，并尝试了解如何使用它们。\n",
    "\n",
    ":::info\n",
    "有关 LangChain 中流式传输技术的更高级别概述，请参阅[概念指南的这一部分](/docs/concepts/streaming)。\n",
    ":::\n",
    "\n",
    "## 使用 Stream\n",
    "\n",
    "所有 `Runnable` 对象都实现了一个名为 `stream` 的同步方法和一个异步变体 `astream`。\n",
    "\n",
    "这些方法旨在以块的形式流式传输最终输出，并在块可用时立即生成每个块。\n",
    "\n",
    "只有当程序中的所有步骤都知道如何处理**输入流**时，流式传输才有可能；即一次处理一个输入块，并生成相应的输出块。\n",
    "\n",
    "这种处理的复杂性可能会有所不同，从简单的任务（如发出 LLM 生成的标记）到更具挑战性的任务（如在整个 JSON 完成之前流式传输 JSON 结果的一部分）。\n",
    "\n",
    "探索流式传输的最佳起点是 LLM 应用程序中最重要的组件——LLM 本身！\n",
    "\n",
    "### LLM 和聊天模型\n",
    "\n",
    "大型语言模型及其聊天变体是基于 LLM 的应用程序中的主要瓶颈。\n",
    "\n",
    "大型语言模型可能需要**几秒钟**才能生成对查询的完整响应。这远远慢于**~200-300 毫秒**的阈值，在该阈值下应用程序对终端用户来说感觉响应迅速。\n",
    "\n",
    "使应用程序感觉更响应的关键策略是显示中间进度；即**逐个标记**流式传输模型的输出。\n",
    "\n",
    "我们将展示使用聊天模型进行流式传输的示例。从以下选项中选择一个：\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs\n",
    "  customVarName=\"model\"\n",
    "/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f123bdcb-8c8b-440c-9bbd-aa5ed4e9cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "keys = [\n",
    "    \"ANTHROPIC_API_KEY\",\n",
    "    \"OPENAI_API_KEY\",\n",
    "]\n",
    "\n",
    "for key in keys:\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass(f\"Enter API Key for {key}=?\")\n",
    "\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-sonnet-20240229\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2464c57-0e89-4159-b21f-5859a21be658",
   "metadata": {},
   "source": [
    "让我们从同步 `stream` API 开始："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44dfb2-0749-487a-8918-f8b6b8233093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| sky| appears| blue| during| the| day|.|"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for chunk in model.stream(\"天空是什么颜色？\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d835b5c-cbb7-41ab-8905-bdc24d515d29",
   "metadata": {},
   "source": [
    "或者，如果您在异步环境中工作，可以考虑使用异步 `astream` API："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f180b6a0-0027-4bd8-8bab-fde76e282609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| sky| appears| blue| during| the| day|.|"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "async for chunk in model.astream(\"天空是什么颜色？\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66730a87-77d5-40d6-a68f-315121989bd1",
   "metadata": {},
   "source": [
    "让我们检查其中一个块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dade3000-1ac4-4f5c-b5c6-a0217f9f8a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The', id='run-b36bea64-5511-4d7a-b6a3-a07b3db0c8e7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a47193-2bd1-46bc-9c7e-ea0f6b08c4a5",
   "metadata": {},
   "source": [
    "我们得到了一个名为 `AIMessageChunk` 的东西。这个块表示 `AIMessage` 的一部分。\n",
    "\n",
    "消息块是设计为可累加的——可以简单地将它们相加以获得到目前为止的响应状态！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3cf5f38-249c-4da0-94e6-5e5203fad52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The sky appears blue during', id='run-b36bea64-5511-4d7a-b6a3-a07b3db0c8e7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffbd9a-3b79-44b6-8883-1371f9460c77",
   "metadata": {},
   "source": [
    "### 链\n",
    "\n",
    "几乎所有 LLM 应用程序都涉及比调用语言模型更多的步骤。\n",
    "\n",
    "让我们使用 `LangChain 表达式语言` (`LCEL`) 构建一个简单的链，该链结合了提示、模型和解析器，并验证流式传输是否有效。\n",
    "\n",
    "我们将使用 [`StrOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) 来解析模型的输出。这是一个简单的解析器，它从 `AIMessageChunk` 中提取 `content` 字段，给我们模型返回的 `token`。\n",
    "\n",
    ":::tip\n",
    "LCEL 是一种*声明式*方式，通过将不同的 LangChain 原语链接在一起来指定“程序”。使用 LCEL 创建的链受益于 `stream` 和 `astream` 的自动实现，允许流式传输最终输出。事实上，使用 LCEL 创建的链实现了整个标准 Runnable 接口。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8562ae2-3fd1-4829-9801-a5a732b1798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here|'s| a| joke| about| a| par|rot|:|\n",
      "\n",
      "A man| goes| to| a| pet| shop| to| buy| a| par|rot|.| The| shop| owner| shows| him| two| stunning| pa|rr|ots| with| beautiful| pl|um|age|.|\n",
      "\n",
      "\"|There|'s| a| talking| par|rot| an|d a| non|-|talking| par|rot|,\"| the| owner| says|.| \"|The| talking| par|rot| costs| $|100|,| an|d the| non|-|talking| par|rot| is| $|20|.\"|\n",
      "\n",
      "The| man| says|,| \"|I|'ll| take| the| non|-|talking| par|rot| at| $|20|.\"|\n",
      "\n",
      "He| pays| an|d leaves| with| the| par|rot|.| As| he|'s| walking| down| the| street|,| the| par|rot| looks| up| at| him| an|d says|,| \"|You| know|,| you| really| are| a| stupi|d man|!\"|\n",
      "\n",
      "The| man| is| stun|ne|d an|d looks| at| the| par|rot| in| dis|bel|ief|.| The| par|rot| continues|,| \"|Yes|,| you| got| r|ippe|d off| big| time|!| I| can| talk| just| as| well| as| that| other| par|rot|,| an|d you| only| pai|d $|20| |for| me|!\"|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"讲一个关于 {topic} 的笑话\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"鹦鹉\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868bc412",
   "metadata": {},
   "source": [
    "请注意，即使我们在上面的链末尾使用了 `parser`，我们仍然获得了流式输出。`parser` 单独处理每个流式块。许多 [LCEL 原语](/docs/how_to#langchain-expression-language-lcel) 也支持这种变换式的透传流式传输，这在构建应用程序时非常方便。\n",
    "\n",
    "可以[设计自定义函数以返回生成器](/docs/how_to/functions#streaming)，这些生成器能够处理流。\n",
    "\n",
    "某些 runnables（如[提示模板](/docs/how_to#prompt-templates)和[聊天模型](/docs/how_to#chat-models)）无法处理单个块，而是聚合所有先前步骤。这些 runnables 可能会中断流式传输过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b399fb4-5e3c-4581-9570-6df9b42b623d",
   "metadata": {},
   "source": [
    ":::note\n",
    "LangChain 表达式语言允许您将链的构建与其使用模式（例如，同步/异步、批处理/流式传输等）分开。如果这与您正在构建的内容无关，您还可以通过\n",
    "分别调用每个组件上的 `invoke`、`batch` 或 `stream`，将结果分配给变量，然后根据需要在下游使用它们，依赖标准**命令式**编程方法。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff2701-8887-486f-8b3b-eb26383d4bb6",
   "metadata": {},
   "source": [
    "### 处理输入流\n",
    "\n",
    "如果您想在生成时流式传输 JSON，该怎么办？\n",
    "\n",
    "如果您依赖 `json.loads` 来解析部分 JSON，由于部分 JSON 不是有效的 JSON，解析将失败。\n",
    "\n",
    "您可能会完全不知道该怎么做，并声称无法流式传输 JSON。\n",
    "\n",
    "事实证明，有一种方法可以做到这一点——解析器需要处理**输入流**，并尝试将部分 JSON“自动完成”为有效状态。\n",
    "\n",
    "让我们看看这样的解析器是如何工作的，以了解这意味着什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff63cce-715a-4561-951f-9321c82e8d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': 'France'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': ''}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan'}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125584}]}\n",
      "{'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351567}, {'name': 'Japan', 'population': 125584000}]}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # 由于旧版本 Langchain 中的一个错误，JsonOutputParser 未从某些模型流式传输结果\n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\"\n",
    "):\n",
    "    print(text, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d4323-a6cf-49be-8779-e8797c5e3b00",
   "metadata": {},
   "source": [
    "现在，让我们**打破**流式传输。我们将使用前面的示例，并在末尾附加一个提取函数，从最终的 JSON 中提取国家名称。\n",
    "\n",
    ":::warning\n",
    "链中的任何步骤如果操作**最终输入**而不是**输入流**，都可能通过 `stream` 或 `astream` 中断流式传输功能。\n",
    ":::\n",
    "\n",
    ":::tip\n",
    "稍后，我们将讨论 `astream_events` API，它从中间步骤流式传输结果。即使链包含仅操作**最终输入**的步骤，此 API 也会从中间步骤流式传输结果。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c90117-9faa-4a01-b484-0db071808d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import (\n",
    "    JsonOutputParser,\n",
    ")\n",
    "\n",
    "\n",
    "# 一个操作最终输入而不是输入流的函数\n",
    "# 它打破了流式传输\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"一个不操作输入流并打破流式传输的函数。\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\"\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6dca2-2027-414d-a196-2db6e3ebb8a5",
   "metadata": {},
   "source": [
    "#### 生成器函数\n",
    "\n",
    "让我们使用一个可以操作**输入流**的生成器函数来修复流式传输。\n",
    "\n",
    ":::tip\n",
    "生成器函数（使用 `yield` 的函数）允许编写操作**输入流**的代码\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15984b2b-315a-4119-945b-2a3dabea3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France|Spain|Japan|"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "async def _extract_country_names_streaming(input_stream):\n",
    "    \"\"\"一个操作输入流的函数。\"\"\"\n",
    "    country_names_so_far = set()\n",
    "\n",
    "    async for input in input_stream:\n",
    "        if not isinstance(input, dict):\n",
    "            continue\n",
    "\n",
    "        if \"countries\" not in input:\n",
    "            continue\n",
    "\n",
    "        countries = input[\"countries\"]\n",
    "\n",
    "        if not isinstance(countries, list):\n",
    "            continue\n",
    "\n",
    "        for country in countries:\n",
    "            name = country.get(\"name\")\n",
    "            if not name:\n",
    "                continue\n",
    "            if name not in country_names_so_far:\n",
    "                yield name\n",
    "                country_names_so_far.add(name)\n",
    "\n",
    "\n",
    "chain = model | JsonOutputParser() | _extract_country_names_streaming\n",
    "\n",
    "async for text in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\",\n",
    "):\n",
    "    print(text, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59823f5-9b9a-43c5-a213-34644e2f1d3d",
   "metadata": {},
   "source": [
    ":::note\n",
    "由于上述代码依赖于 JSON 自动完成，您可能会看到国家名称的部分名称（例如 `Sp` 和 `Spain`），这不是提取结果所希望的！\n",
    "\n",
    "我们专注于流式传输概念，而不一定是链的结果。\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adf65b7-aa47-4321-98c7-a0abe43b833a",
   "metadata": {},
   "source": [
    "### 非流式组件\n",
    "\n",
    "某些内置组件（如检索器）不提供任何`流式传输`。如果我们尝试对它们进行`流式传输`会发生什么？🤨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1c00d-8b44-40d0-9e2b-8a70d238f82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(page_content='harrison worked at kensho'),\n",
       "  Document(page_content='harrison likes spicy food')]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "template = \"\"\"仅根据以下上下文回答问题：\n",
    "{context}\n",
    "\n",
    "问题：{question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison 在 kensho 工作过\", \"harrison 喜欢辛辣食物\"],\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chunks = [chunk for chunk in retriever.stream(\"harrison 在哪里工作过？\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3e71b-439e-418f-8a8a-5232fba3d9fd",
   "metadata": {},
   "source": [
    "Stream 仅从该组件生成最终结果。\n",
    "\n",
    "这没问题 🥹！并非所有组件都必须实现流式传输——在某些情况下，流式传输要么不必要，要么困难，要么没有意义。\n",
    "\n",
    ":::tip\n",
    "使用非流式组件构建的 LCEL 链，在很多情况下仍然能够流式传输，流式传输部分输出通常从链中的最后一个非流式步骤开始。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "957447e6-1e60-41ef-8c10-2654bd9e738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = (\n",
    "    {\n",
    "        \"context\": retriever.with_config(run_name=\"Docs\"),\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e50b5d-bf51-4eee-9da0-ee40dd9ce42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base|d on| the| given| context|,| Harrison| worke|d at| K|ens|ho|.|\n",
      "\n",
      "Here| are| |3| |made| up| sentences| about| this| place|:|\n",
      "\n",
      "1|.| K|ens|ho| was| a| cutting|-|edge| technology| company| known| for| its| innovative| solutions| in| artificial| intelligence| an|d data| analytics|.|\n",
      "\n",
      "2|.| The| modern| office| space| at| K|ens|ho| feature|d open| floor| plans|,| collaborative| work|sp|aces|,| an|d a| vib|rant| atmosphere| that| fos|tere|d creativity| an|d team|work|.|\n",
      "\n",
      "3|.| With| its| prime| location| in| the| heart| of| the| city|,| K|ens|ho| attracte|d top| talent| from| aroun|d the| worl|d,| creating| a| diverse| an|d dynamic| work| environment|.|"
     ]
    }
   ],
   "source": [
    "for chunk in retrieval_chain.stream(\n",
    "    \"harrison 在哪里工作过？ \" \"写 3 个关于这个地方的虚构句子。\"\n",
    "):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657aa4e-3469-4b5b-a09c-60b53a23b1e7",
   "metadata": {},
   "source": [
    "现在我们已经了解了 `stream` 和 `astream` 的工作原理，让我们进入流式事件的世界。 🏞️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baceb5c0-d4a4-4b98-8733-80ae4407b62d",
   "metadata": {},
   "source": [
    "## 使用 Stream Events\n",
    "\n",
    "事件流式传输是一个**测试版** API。根据反馈，此 API 可能会有所变化。\n",
    "\n",
    ":::note\n",
    "\n",
    "本指南演示了 `V2` API，需要 langchain-core >= 0.2。有关与旧版本 LangChain 兼容的 `V1` API，请参阅[此处](https://python.langchain.com/v0.1/docs/expression_language/streaming/#using-stream-events)。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61348df9-ec58-401e-be89-68a70042f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core\n",
    "\n",
    "langchain_core.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9e983-bbde-4906-9eca-4ccc06eabd91",
   "metadata": {},
   "source": [
    "为了使 `astream_events` API 正常工作：\n",
    "\n",
    "* 尽可能在代码中使用 `async`（例如，异步工具等）\n",
    "* 如果定义自定义函数/运行对象，请传播回调\n",
    "* 如果未使用 LCEL 的情况下使用运行对象，请确保在 LLM 上调用 `.astream()` 而不是 `.ainvoke` 以强制 LLM 流式传输标记。\n",
    "* 如果有任何问题，请告诉我们！ :)\n",
    "\n",
    "### 事件参考\n",
    "\n",
    "以下是一个参考表，显示了各种 Runnable 对象可能发出的某些事件。\n",
    "\n",
    "\n",
    ":::note\n",
    "当流式传输实现正确时，运行对象的输入在输入流完全消耗之前将未知。这意味着 `inputs` 通常仅包含在 `end` 事件中，而不是 `start` 事件中。\n",
    ":::\n",
    "\n",
    "| 事件                | 名称             | 块                           | 输入                                         | 输出                                          |\n",
    "|----------------------|------------------|---------------------------------|-----------------------------------------------|-------------------------------------------------|\n",
    "| on_chat_model_start  | [模型名称]     |                                 | \\{\"messages\": [[SystemMessage, HumanMessage]]\\} |                                                 |\n",
    "| on_chat_model_stream | [模型名称]     | AIMessageChunk(content=\"hello\") |                                               |                                                 |\n",
    "| on_chat_model_end    | [模型名称]     |                                 | \\{\"messages\": [[SystemMessage, HumanMessage]]\\} | AIMessageChunk(content=\"hello world\")           |\n",
    "| on_llm_start         | [模型名称]     |                                 | \\{'input': 'hello'\\}                            |                                                 |\n",
    "| on_llm_stream        | [模型名称]     | 'Hello'                         |                                               |                                                 |\n",
    "| on_llm_end           | [模型名称]     |                                 | 'Hello human!'                                |                                                 |\n",
    "| on_chain_start       | format_docs      |                                 |                                               |                                                 |\n",
    "| on_chain_stream      | format_docs      | \"hello world!, goodbye world!\"  |                                               |                                                 |\n",
    "| on_chain_end         | format_docs      |                                 | [Document(...)]                               | \"hello world!, goodbye world!\"                  |\n",
    "| on_tool_start        | some_tool        |                                 | \\{\"x\": 1, \"y\": \"2\"\\}                            |                                                 |\n",
    "| on_tool_end          | some_tool        |                                 |                                               | \\{\"x\": 1, \"y\": \"2\"\\}                              |\n",
    "| on_retriever_start   | [检索器名称] |                                 | \\{\"query\": \"hello\"\\}                            |                                                 |\n",
    "| on_retriever_end     | [检索器名称] |                                 | \\{\"query\": \"hello\"\\}                            | [Document(...), ..]                             |\n",
    "| on_prompt_start      | [模板名称]  |                                 | \\{\"question\": \"hello\"\\}                         |                                                 |\n",
    "| on_prompt_end        | [模板名称]  |                                 | \\{\"question\": \"hello\"\\}                         | ChatPromptValue(messages: [SystemMessage, ...]) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ec135-3348-4041-8f55-bf3e59b3b2d0",
   "metadata": {},
   "source": [
    "### 聊天模型\n",
    "\n",
    "让我们首先看看聊天模型生成的事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab5f910-fee0-4a94-9f05-b469006333b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []\n",
    "async for event in model.astream_events(\"你好\"):\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32972939-2995-4b2e-84db-045adb044fad",
   "metadata": {},
   "source": [
    ":::note\n",
    "\n",
    "对于 `langchain-core<0.3.37`，显式设置 `version` 参数（例如，`model.astream_events(\"hello\", version=\"v2\")`）。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b8f47-da78-4569-a49a-53a8efaa26bc",
   "metadata": {},
   "source": [
    "让我们看看几个开始事件和几个结束事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4a2f5dc-2c75-4be4-a8ca-b5b84a3cdbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_start',\n",
       "  'data': {'input': 'hello'},\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': [],\n",
       "  'run_id': 'b18d016d-8b9b-49e7-a555-44db498fcf66',\n",
       "  'metadata': {'ls_provider': 'anthropic',\n",
       "   'ls_model_name': 'claude-3-sonnet-20240229',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.0,\n",
       "   'ls_max_tokens': 1024},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': 'b18d016d-8b9b-49e7-a555-44db498fcf66',\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'anthropic',\n",
       "   'ls_model_name': 'claude-3-sonnet-20240229',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.0,\n",
       "   'ls_max_tokens': 1024},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-b18d016d-8b9b-49e7-a555-44db498fcf66', usage_metadata={'input_tokens': 8, 'output_tokens': 4, 'total_tokens': 12, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'run_id': 'b18d016d-8b9b-49e7-a555-44db498fcf66',\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'anthropic',\n",
       "   'ls_model_name': 'claude-3-sonnet-20240229',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.0,\n",
       "   'ls_max_tokens': 1024},\n",
       "  'data': {'chunk': AIMessageChunk(content='Hello! How can', additional_kwargs={}, response_metadata={}, id='run-b18d016d-8b9b-49e7-a555-44db498fcf66')},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cfe826-ee63-4310-ad48-55a95eb3b9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chat_model_stream',\n",
       "  'run_id': 'b18d016d-8b9b-49e7-a555-44db498fcf66',\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'anthropic',\n",
       "   'ls_model_name': 'claude-3-sonnet-20240229',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.0,\n",
       "   'ls_max_tokens': 1024},\n",
       "  'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None}, id='run-b18d016d-8b9b-49e7-a555-44db498fcf66', usage_metadata={'input_tokens': 0, 'output_tokens': 12, 'total_tokens': 12, 'input_token_details': {}})},\n",
       "  'parent_ids': []},\n",
       " {'event': 'on_chat_model_end',\n",
       "  'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None}, id='run-b18d016d-8b9b-49e7-a555-44db498fcf66', usage_metadata={'input_tokens': 8, 'output_tokens': 16, 'total_tokens': 24, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})},\n",
       "  'run_id': 'b18d016d-8b9b-49e7-a555-44db498fcf66',\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': [],\n",
       "  'metadata': {'ls_provider': 'anthropic',\n",
       "   'ls_model_name': 'claude-3-sonnet-20240229',\n",
       "   'ls_model_type': 'chat',\n",
       "   'ls_temperature': 0.0,\n",
       "   'ls_max_tokens': 1024},\n",
       "  'parent_ids': []}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8f173-e9c7-4c27-81a5-b7c85c12714d",
   "metadata": {},
   "source": [
    "### 链\n",
    "\n",
    "让我们重新审视解析流式 JSON 的示例链，以探索流式事件 API。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328c56c-a303-427b-b1f2-f354e9af555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    model | JsonOutputParser()\n",
    ")  # 由于旧版本 Langchain 中的一个错误，JsonOutputParser 未从某些模型流式传输结果\n",
    "\n",
    "events = [\n",
    "    event\n",
    "    async for event in chain.astream_events(\n",
    "        \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "        '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "        \"每个国家应该有键 `name` 和 `population`\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc00b99-a961-4221-a3c7-9d807114bbfb",
   "metadata": {},
   "source": [
    "如果您检查前几个事件，您会注意到有**3**个不同的开始事件，而不是**2**个开始事件。\n",
    "\n",
    "这三个开始事件对应于：\n",
    "\n",
    "1. 链（模型 + 解析器）\n",
    "2. 模型\n",
    "3. 解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e66ea3d-a450-436a-aaac-d9478abc6c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': 'on_chain_start',\n",
       "  'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'},\n",
       "  'name': 'RunnableSequence',\n",
       "  'tags': [],\n",
       "  'run_id': '4765006b-16e2-4b1d-a523-edd9fd64cb92',\n",
       "  'metadata': {}},\n",
       " {'event': 'on_chat_model_start',\n",
       "  'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`')]]}},\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'run_id': '0320c234-7b52-4a14-ae4e-5f100949e589',\n",
       "  'metadata': {}},\n",
       " {'event': 'on_chat_model_stream',\n",
       "  'data': {'chunk': AIMessageChunk(content='{', id='run-0320c234-7b52-4a14-ae4e-5f100949e589')},\n",
       "  'run_id': '0320c234-7b52-4a14-ae4e-5f100949e589',\n",
       "  'name': 'ChatAnthropic',\n",
       "  'tags': ['seq:step:1'],\n",
       "  'metadata': {}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8512238-d035-4acd-9248-a8570da064c9",
   "metadata": {},
   "source": [
    "如果您查看最后 3 个事件，您会看到什么？中间的事件呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c742cfa4-9b03-4a5b-96d9-5fe56e95e3b4",
   "metadata": {},
   "source": [
    "让我们使用此 API 输出模型和解析器的流式事件。我们忽略了开始事件、结束事件和链的事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c71d6-8d94-4ce0-a78a-f20e90f628df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: '{'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: '\\n  \"countries'\n",
      "Chat model chunk: '\": [\\n    '\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '{\\n      \"'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: 'name\": \"France'\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Chat model chunk: '\",\\n      \"'\n",
      "Chat model chunk: 'population\": 67'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67}]}\n",
      "Chat model chunk: '413'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413}]}\n",
      "Chat model chunk: '000\\n    },'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}]}\n",
      "Chat model chunk: '\\n    {'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}, {}]}\n",
      "Chat model chunk: '\\n      \"name\":'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"聊天模型块: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"解析器块: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # 截断输出\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798ea891-997c-454c-bf60-43124f40ee1b",
   "metadata": {},
   "source": [
    "由于模型和解析器都支持流式传输，我们实时看到来自两个组件的流式事件！很酷吧？🦜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084148b-bcdc-4373-9caa-6568f03e7b23",
   "metadata": {},
   "source": [
    "### 过滤事件\n",
    "\n",
    "由于此 API 生成了许多事件，因此能够过滤事件非常有用。\n",
    "\n",
    "您可以按组件`名称`、组件`标签`或组件`类型`进行过滤。\n",
    "\n",
    "#### 按名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42145735-25e8-4e67-b081-b0c15ea45dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_parser_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'my_parser', 'tags': ['seq:step:2'], 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'metadata': {}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France'}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}, {}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain'}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "{'event': 'on_parser_stream', 'run_id': '37ee9e85-481c-415e-863b-c9e132d24948', 'name': 'my_parser', 'tags': ['seq:step:2'], 'metadata': {}, 'data': {'chunk': {'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47}]}}, 'parent_ids': ['5a0bc625-09fd-4bdf-9932-54909a9a8c29']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\",\n",
    "    include_names=[\"my_parser\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # 截断输出\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d5626-7dba-4eb3-ad81-76c1092c5146",
   "metadata": {},
   "source": [
    "#### 按类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7d8fe0-47ca-4ab4-9c10-b34e3f6106ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'model', 'tags': ['seq:step:1'], 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c', usage_metadata={'input_tokens': 56, 'output_tokens': 1, 'total_tokens': 57, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\\n  \"countries', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\": [\\n    ', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{\\n      \"', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='name\": \"France', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\",\\n      \"', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='population\": 67', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='413', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='000\\n    },', additional_kwargs={}, response_metadata={}, id='run-156c3e40-82fb-49ff-8e41-9e998061be8c')}, 'run_id': '156c3e40-82fb-49ff-8e41-9e998061be8c', 'name': 'model', 'tags': ['seq:step:1'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['7b927055-bc1b-4b50-a34c-10d3cfcb3899']}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = model.with_config({\"run_name\": \"model\"}) | JsonOutputParser().with_config(\n",
    "    {\"run_name\": \"my_parser\"}\n",
    ")\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    '以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。每个国家应该有键 `name` 和 `population`',\n",
    "    include_types=[\"chat_model\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # 截断输出\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec8dd4-9b5b-4000-b63f-5845bfc5a065",
   "metadata": {},
   "source": [
    "#### 按标签\n",
    "\n",
    ":::caution\n",
    "\n",
    "标签由给定运行对象的子组件继承。\n",
    "\n",
    "如果您使用标签进行过滤，请确保这是您想要的。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237c218-5fd6-4146-ac68-020a038cf582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`'}, 'name': 'RunnableSequence', 'tags': ['my_chain'], 'run_id': '58d1302e-36ce-4df7-a3cb-47cb73d57e44', 'metadata': {}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_start', 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of \"countries\" which contains a list of countries. Each country should have the key `name` and `population`', additional_kwargs={}, response_metadata={})]]}}, 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'run_id': '8222e8a1-d978-4f30-87fc-b2dba838774b', 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-8222e8a1-d978-4f30-87fc-b2dba838774b', usage_metadata={'input_tokens': 56, 'output_tokens': 1, 'total_tokens': 57, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'run_id': '8222e8a1-d978-4f30-87fc-b2dba838774b', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_parser_start', 'data': {}, 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'run_id': '75604c84-e1e6-494a-8b2a-950f45d932e8', 'metadata': {}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='{', additional_kwargs={}, response_metadata={}, id='run-8222e8a1-d978-4f30-87fc-b2dba838774b')}, 'run_id': '8222e8a1-d978-4f30-87fc-b2dba838774b', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_parser_stream', 'run_id': '75604c84-e1e6-494a-8b2a-950f45d932e8', 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_chain_stream', 'run_id': '58d1302e-36ce-4df7-a3cb-47cb73d57e44', 'name': 'RunnableSequence', 'tags': ['my_chain'], 'metadata': {}, 'data': {'chunk': {}}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\\n  \"countries', additional_kwargs={}, response_metadata={}, id='run-8222e8a1-d978-4f30-87fc-b2dba838774b')}, 'run_id': '8222e8a1-d978-4f30-87fc-b2dba838774b', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_chat_model_stream', 'data': {'chunk': AIMessageChunk(content='\": [\\n    ', additional_kwargs={}, response_metadata={}, id='run-8222e8a1-d978-4f30-87fc-b2dba838774b')}, 'run_id': '8222e8a1-d978-4f30-87fc-b2dba838774b', 'name': 'ChatAnthropic', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-sonnet-20240229', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 1024}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_parser_stream', 'run_id': '75604c84-e1e6-494a-8b2a-950f45d932e8', 'name': 'JsonOutputParser', 'tags': ['seq:step:2', 'my_chain'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': ['58d1302e-36ce-4df7-a3cb-47cb73d57e44']}\n",
      "{'event': 'on_chain_stream', 'run_id': '58d1302e-36ce-4df7-a3cb-47cb73d57e44', 'name': 'RunnableSequence', 'tags': ['my_chain'], 'metadata': {}, 'data': {'chunk': {'countries': []}}, 'parent_ids': []}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "chain = (model | JsonOutputParser()).with_config({\"tags\": [\"my_chain\"]})\n",
    "\n",
    "max_events = 0\n",
    "async for event in chain.astream_events(\n",
    "    '以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。每个国家应该有键 `name` 和 `population`',\n",
    "    include_tags=[\"my_chain\"],\n",
    "):\n",
    "    print(event)\n",
    "    max_events += 1\n",
    "    if max_events > 10:\n",
    "        # 截断输出\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e54c4-61a2-4f6c-aa68-d2b09b5e1d4f",
   "metadata": {},
   "source": [
    "### 非流式组件\n",
    "\n",
    "还记得某些组件由于不操作**输入流**而无法很好地流式传输吗？\n",
    "\n",
    "虽然使用 `astream` 时此类组件可能会中断最终输出的流式传输，但 `astream_events` 仍会从支持流式传输的中间步骤生成流式事件！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6451d3-3b11-4a71-ae19-998f4c10180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不支持流式传输的函数。\n",
    "# 它操作最终输入而不是\n",
    "# 操作输入流。\n",
    "def _extract_country_names(inputs):\n",
    "    \"\"\"一个不操作输入流并打破流式传输的函数。\"\"\"\n",
    "    if not isinstance(inputs, dict):\n",
    "        return \"\"\n",
    "\n",
    "    if \"countries\" not in inputs:\n",
    "        return \"\"\n",
    "\n",
    "    countries = inputs[\"countries\"]\n",
    "\n",
    "    if not isinstance(countries, list):\n",
    "        return \"\"\n",
    "\n",
    "    country_names = [\n",
    "        country.get(\"name\") for country in countries if isinstance(country, dict)\n",
    "    ]\n",
    "    return country_names\n",
    "\n",
    "\n",
    "chain = (\n",
    "    model | JsonOutputParser() | _extract_country_names\n",
    ")  # 此解析器目前仅适用于 OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a972e1a6-80cd-4d59-90a0-73563f1503d4",
   "metadata": {},
   "source": [
    "正如预期的那样，`astream` API 无法正常工作，因为 `_extract_country_names` 不操作流。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a8fe35-faab-4970-b8c0-5c780845d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France', 'Spain', 'Japan']\n"
     ]
    }
   ],
   "source": [
    "async for chunk in chain.astream(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\",\n",
    "):\n",
    "    print(chunk, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b279ea33-54f1-400a-acb1-b8445ccbf1fa",
   "metadata": {},
   "source": [
    "现在，让我们确认使用 astream_events 我们仍然可以看到来自模型和解析器的流式输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83701e-b801-429f-b2ac-47ed44d2d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model chunk: ''\n",
      "Chat model chunk: '{'\n",
      "Parser chunk: {}\n",
      "Chat model chunk: '\\n  \"countries'\n",
      "Chat model chunk: '\": [\\n    '\n",
      "Parser chunk: {'countries': []}\n",
      "Chat model chunk: '{\\n      \"'\n",
      "Parser chunk: {'countries': [{}]}\n",
      "Chat model chunk: 'name\": \"France'\n",
      "Parser chunk: {'countries': [{'name': 'France'}]}\n",
      "Chat model chunk: '\",\\n      \"'\n",
      "Chat model chunk: 'population\": 67'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67}]}\n",
      "Chat model chunk: '413'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413}]}\n",
      "Chat model chunk: '000\\n    },'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}]}\n",
      "Chat model chunk: '\\n    {'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}, {}]}\n",
      "Chat model chunk: '\\n      \"name\":'\n",
      "Chat model chunk: ' \"Spain\",'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain'}]}\n",
      "Chat model chunk: '\\n      \"population\":'\n",
      "Chat model chunk: ' 47'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47}]}\n",
      "Chat model chunk: '351'\n",
      "Parser chunk: {'countries': [{'name': 'France', 'population': 67413000}, {'name': 'Spain', 'population': 47351}]}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "num_events = 0\n",
    "\n",
    "async for event in chain.astream_events(\n",
    "    \"以 JSON 格式输出法国、西班牙和日本的国家及其人口的列表。 \"\n",
    "    '使用一个外部键为 \"countries\" 的字典，其中包含一个国家列表。 '\n",
    "    \"每个国家应该有键 `name` 和 `population`\",\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        print(\n",
    "            f\"聊天模型块: {repr(event['data']['chunk'].content)}\",\n",
    "            flush=True,\n",
    "        )\n",
    "    if kind == \"on_parser_stream\":\n",
    "        print(f\"解析器块: {event['data']['chunk']}\", flush=True)\n",
    "    num_events += 1\n",
    "    if num_events > 30:\n",
    "        # 截断输出\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91bdd3-f4a3-4b3c-b21a-26365c6c1566",
   "metadata": {},
   "source": [
    "### 传播回调\n",
    "\n",
    ":::caution\n",
    "如果您在工具中调用运行对象，则需要将回调传播到运行对象；否则，不会生成任何流式事件。\n",
    ":::\n",
    "\n",
    ":::note\n",
    "使用 `RunnableLambdas` 或 `@chains` 装饰器时，回调会在后台自动传播。\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854206d-b3a5-4f91-9e00-bccbaebac61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'bad_tool', 'tags': [], 'run_id': 'ea900472-a8f7-425d-b627-facdef936ee8', 'metadata': {}}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '77b01284-0515-48f4-8d7c-eb27c1882f86', 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '77b01284-0515-48f4-8d7c-eb27c1882f86', 'name': 'reverse_word', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'ea900472-a8f7-425d-b627-facdef936ee8', 'name': 'bad_tool', 'tags': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "def reverse_word(word: str):\n",
    "    return word[::-1]\n",
    "\n",
    "\n",
    "reverse_word = RunnableLambda(reverse_word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def bad_tool(word: str):\n",
    "    \"\"\"不正确传播回调的自定义工具。\"\"\"\n",
    "    return reverse_word.invoke(word)\n",
    "\n",
    "\n",
    "async for event in bad_tool.astream_events(\"你好\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e68a99-7886-465b-8575-116022857469",
   "metadata": {},
   "source": [
    "以下是正确传播回调的重新实现。您会注意到，现在我们也从 `reverse_word` 运行对象中获取事件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a6cb3-bb43-465c-8cfc-0a7349d70968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_tool_start', 'data': {'input': 'hello'}, 'name': 'correct_tool', 'tags': [], 'run_id': 'd5ea83b9-9278-49cc-9f1d-aa302d671040', 'metadata': {}}\n",
      "{'event': 'on_chain_start', 'data': {'input': 'hello'}, 'name': 'reverse_word', 'tags': [], 'run_id': '44dafbf4-2f87-412b-ae0e-9f71713810df', 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': 'olleh', 'input': 'hello'}, 'run_id': '44dafbf4-2f87-412b-ae0e-9f71713810df', 'name': 'reverse_word', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_tool_end', 'data': {'output': 'olleh'}, 'run_id': 'd5ea83b9-9278-49cc-9f1d-aa302d671040', 'name': 'correct_tool', 'tags': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def correct_tool(word: str, callbacks):\n",
    "    \"\"\"正确传播回调的工具。\"\"\"\n",
    "    return reverse_word.invoke(word, {\"callbacks\": callbacks})\n",
    "\n",
    "\n",
    "async for event in correct_tool.astream_events(\"你好\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640daa94-e4fe-4997-ab6e-45120f18b9ee",
   "metadata": {},
   "source": [
    "如果您从 Runnable Lambdas 或 `@chains` 中调用运行对象，则回调会自动为您传递。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ac0a3c1-f3a4-4157-b053-4fec8d2e698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'metadata': {}}\n",
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': '5cf26fc8-840b-4642-98ed-623dda28707a', 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': '5cf26fc8-840b-4642-98ed-623dda28707a', 'name': 'reverse_word', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_chain_stream', 'data': {'chunk': '43214321'}, 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '03b0e6a1-3e60-42fc-8373-1e7829198d80', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "reverse_and_double = RunnableLambda(reverse_and_double)\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a34268-9b3d-4857-b4ed-65d95f4a1293",
   "metadata": {},
   "source": [
    "使用 `@chain` 装饰器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c896bb94-9d10-41ff-8fe2-d6b05b1ed74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_and_double', 'tags': [], 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'metadata': {}}\n",
      "{'event': 'on_chain_start', 'data': {'input': '1234'}, 'name': 'reverse_word', 'tags': [], 'run_id': '64fc99f0-5d7d-442b-b4f5-4537129f67d1', 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': '4321', 'input': '1234'}, 'run_id': '64fc99f0-5d7d-442b-b4f5-4537129f67d1', 'name': 'reverse_word', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_chain_stream', 'data': {'chunk': '43214321'}, 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}\n",
      "{'event': 'on_chain_end', 'data': {'output': '43214321'}, 'run_id': '1bfcaedc-f4aa-4d8e-beee-9bba6ef17008', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "async def reverse_and_double(word: str):\n",
    "    return await reverse_word.ainvoke(word) * 2\n",
    "\n",
    "\n",
    "await reverse_and_double.ainvoke(\"1234\")\n",
    "\n",
    "async for event in reverse_and_double.astream_events(\"1234\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3efcd9",
   "metadata": {},
   "source": [
    "## 下一步\n",
    "\n",
    "现在您已经了解了一些使用 LangChain 流式传输最终输出和内部步骤的方法。\n",
    "\n",
    "要了解更多信息，请查看本节中的其他操作指南或[Langchain 表达式语言的概念指南](/docs/concepts/lcel/)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
