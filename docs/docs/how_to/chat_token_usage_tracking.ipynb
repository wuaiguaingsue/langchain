{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5715368",
   "metadata": {},
   "source": [
    "# 如何在ChatModels中跟踪令牌使用情况\n",
    "\n",
    ":::info 前提条件\n",
    "\n",
    "本指南假设您熟悉以下概念：\n",
    "- [聊天模型](/docs/concepts/chat_models)\n",
    "\n",
    ":::\n",
    "\n",
    "跟踪[令牌](/docs/concepts/tokens/)使用情况以计算成本是将应用程序投入生产的重要部分。本指南介绍如何从LangChain模型调用中获取此信息。\n",
    "\n",
    "本指南需要 `langchain-anthropic` 和 `langchain-openai >= 0.3.11`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d1338-dd1b-4d06-b33d-d5cffc49fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-anthropic langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b676a",
   "metadata": {},
   "source": [
    ":::note 关于OpenAI流式传输的说明\n",
    "\n",
    "OpenAI的聊天补全API默认情况下不会流式传输令牌使用统计信息（参见API参考文档\n",
    "[此处](https://platform.openai.com/docs/api-reference/completions/create#completions-create-stream_options))。\n",
    "要在使用`ChatOpenAI`或`AzureChatOpenAI`进行流式传输时恢复令牌计数，请设置`stream_usage=True`，\n",
    "如本指南所示。\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ae1e2-a52d-4459-81fd-cdc68b06742a",
   "metadata": {},
   "source": [
    "## 使用LangSmith\n",
    "\n",
    "您可以使用[LangSmith](https://www.langchain.com/langsmith)帮助跟踪LLM应用程序中的令牌使用情况。请参阅[LangSmith快速入门指南](https://docs.smith.langchain.com/)。\n",
    "\n",
    "## 使用AIMessage.usage_metadata\n",
    "\n",
    "许多模型提供商会在聊天生成响应中返回令牌使用信息。在可用时，这些信息将包含在相应模型产生的`AIMessage`对象中。\n",
    "\n",
    "LangChain的`AIMessage`对象包含[usage_metadata](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.usage_metadata)属性。当填充时，该属性将是一个包含标准键（例如，`\"input_tokens\"`和`\"output_tokens\"`）的[UsageMetadata](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.UsageMetadata.html)字典。它们还将包括关于缓存的令牌使用情况和来自多模态数据的令牌信息。\n",
    "\n",
    "例子：\n",
    "\n",
    "**OpenAI**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39bf807-4125-4db4-bbf7-28a46afff6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(model=\"gpt-4o-mini\")\n",
    "openai_response = llm.invoke(\"hello\")\n",
    "openai_response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2299c44a-2fe6-4d52-a6a2-99ff6d231c73",
   "metadata": {},
   "source": [
    "**Anthropic**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c82ff80-ec4e-4049-b019-5f0bbd7df82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 8, 'output_tokens': 12, 'total_tokens': 20}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "anthropic_response = llm.invoke(\"hello\")\n",
    "anthropic_response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef2c43-0ff6-49eb-9782-e4070c9da8d7",
   "metadata": {},
   "source": [
    "### 流式传输\n",
    "\n",
    "一些提供商在流式传输上下文中支持令牌计数元数据。\n",
    "\n",
    "#### OpenAI\n",
    "\n",
    "例如，OpenAI将在流的末尾返回一个带有令牌使用信息的消息[块](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.ai.AIMessageChunk.html)。这种行为由`langchain-openai >= 0.1.9`支持，并可通过设置`stream_usage=True`启用。此属性也可以在实例化`ChatOpenAI`时设置。\n",
    "\n",
    ":::note\n",
    "默认情况下，流中的最后一个消息块将在消息的`response_metadata`属性中包含一个`\"finish_reason\"`。如果我们在流式模式中包含令牌使用情况，将在流的末尾添加一个包含使用元数据的额外块，这样`\"finish_reason\"`会出现在倒数第二个消息块上。\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f0c872-6b6c-4fed-a129-9b5a858505be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content='Hello' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content='!' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' How' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' can' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' I' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' assist' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' you' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content=' today' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content='?' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini'} id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623'\n",
      "content='' id='run-adb20c31-60c7-43a2-99b2-d4a53ca5f623' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}\n"
     ]
    }
   ],
   "source": [
    "llm = init_chat_model(model=\"gpt-4o-mini\")\n",
    "\n",
    "aggregate = None\n",
    "for chunk in llm.stream(\"hello\", stream_usage=True):\n",
    "    print(chunk)\n",
    "    aggregate = chunk if aggregate is None else aggregate + chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd809ded-8b13-4d5f-be5e-277b79d51802",
   "metadata": {},
   "source": [
    "请注意，使用元数据将包含在各个消息块的总和中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db7bc03-a7d4-4704-92ab-f8ba92ef59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n",
      "{'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17}\n"
     ]
    }
   ],
   "source": [
    "print(aggregate.content)\n",
    "print(aggregate.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba63e8-0ed7-4533-8f0f-78e19c38a25c",
   "metadata": {},
   "source": [
    "要禁用OpenAI的流式令牌计数，请将`stream_usage`设置为False，或从参数中省略它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67117f2b-ce68-4c1e-9556-2d3849f90e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content='Hello' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content='!' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' How' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' can' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' I' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' assist' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' you' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content=' today' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content='?' id='run-8e758550-94b0-4cca-a298-57482793c25d'\n",
      "content='' response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini'} id='run-8e758550-94b0-4cca-a298-57482793c25d'\n"
     ]
    }
   ],
   "source": [
    "aggregate = None\n",
    "for chunk in llm.stream(\"hello\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d9617-be3a-419a-9276-de9c29fa50ae",
   "metadata": {},
   "source": [
    "您还可以通过在实例化聊天模型时设置`stream_usage`来启用流式令牌使用。这在将聊天模型整合到LangChain[链](/docs/concepts/lcel)中时非常有用：在[流式传输中间步骤](/docs/how_to/streaming#using-stream-events)或使用如[LangSmith](https://docs.smith.langchain.com/)这样的跟踪软件时可以监控使用元数据。\n",
    "\n",
    "请参阅下面的示例，我们将输出结构化为所需的模式，但仍然可以观察从中间步骤流式传输的令牌使用情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1523d8-127e-4314-82fa-bd97aca37f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token usage: {'input_tokens': 79, 'output_tokens': 23, 'total_tokens': 102}\n",
      "\n",
      "setup='Why was the math book sad?' punchline='Because it had too many problems.'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    stream_usage=True,\n",
    ")\n",
    "# Under the hood, .with_structured_output binds tools to the\n",
    "# chat model and appends a parser.\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "async for event in structured_llm.astream_events(\"Tell me a joke\"):\n",
    "    if event[\"event\"] == \"on_chat_model_end\":\n",
    "        print(f'Token usage: {event[\"data\"][\"output\"].usage_metadata}\\n')\n",
    "    elif event[\"event\"] == \"on_chain_end\" and event[\"name\"] == \"RunnableSequence\":\n",
    "        print(event[\"data\"][\"output\"])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8d313-4bef-463e-89a5-236d8bb6ab2f",
   "metadata": {},
   "source": [
    "在对应的[LangSmith跟踪](https://smith.langchain.com/public/fe6513d5-7212-4045-82e0-fefa28bc7656/r)中，令牌使用情况也可以在聊天模型的负载中看到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6845407-af25-4eed-bc3e-50925c6661e0",
   "metadata": {},
   "source": [
    "## 使用回调函数\n",
    "\n",
    ":::info 需要 ``langchain-core>=0.3.49``\n",
    "\n",
    ":::\n",
    "\n",
    "LangChain实现了一个回调处理程序和上下文管理器，可以跟踪任何返回`usage_metadata`的聊天模型的令牌使用情况。\n",
    "\n",
    "还有一些特定API的回调上下文管理器，它们为不同的模型维护价格信息，允许实时估算成本。目前这些只为OpenAI API和Bedrock Anthropic API实现，并可在`langchain-community`中使用：\n",
    "\n",
    "- [get_openai_callback](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.manager.get_openai_callback.html)\n",
    "- [get_bedrock_anthropic_callback](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.manager.get_bedrock_anthropic_callback.html)\n",
    "\n",
    "下面，我们演示通用的使用元数据回调管理器。我们可以通过配置或作为上下文管理器来跟踪令牌使用情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f043cb9",
   "metadata": {},
   "source": [
    "### 通过配置跟踪令牌使用情况\n",
    "\n",
    "要通过配置跟踪令牌使用情况，实例化一个`UsageMetadataCallbackHandler`并将其传递给配置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b04a4486-72fd-48ce-8f9e-5d281b441195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4o-mini-2024-07-18': {'input_tokens': 8,\n",
       "  'output_tokens': 10,\n",
       "  'total_tokens': 18,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}},\n",
       " 'claude-3-5-haiku-20241022': {'input_tokens': 8,\n",
       "  'output_tokens': 21,\n",
       "  'total_tokens': 29,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.callbacks import UsageMetadataCallbackHandler\n",
    "\n",
    "llm_1 = init_chat_model(model=\"openai:gpt-4o-mini\")\n",
    "llm_2 = init_chat_model(model=\"anthropic:claude-3-5-haiku-latest\")\n",
    "\n",
    "callback = UsageMetadataCallbackHandler()\n",
    "result_1 = llm_1.invoke(\"Hello\", config={\"callbacks\": [callback]})\n",
    "result_2 = llm_2.invoke(\"Hello\", config={\"callbacks\": [callback]})\n",
    "callback.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a290085-e541-4233-afe4-637ec5032bfd",
   "metadata": {},
   "source": [
    "### 使用上下文管理器跟踪令牌使用情况\n",
    "\n",
    "您还可以使用`get_usage_metadata_callback`创建一个上下文管理器并在其中聚合使用元数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4728f55a-24e1-48cd-a195-09d037821b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gpt-4o-mini-2024-07-18': {'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}, 'claude-3-5-haiku-20241022': {'input_tokens': 8, 'output_tokens': 21, 'total_tokens': 29, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.callbacks import get_usage_metadata_callback\n",
    "\n",
    "llm_1 = init_chat_model(model=\"openai:gpt-4o-mini\")\n",
    "llm_2 = init_chat_model(model=\"anthropic:claude-3-5-haiku-latest\")\n",
    "\n",
    "with get_usage_metadata_callback() as cb:\n",
    "    llm_1.invoke(\"Hello\")\n",
    "    llm_2.invoke(\"Hello\")\n",
    "    print(cb.usage_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab6d27",
   "metadata": {},
   "source": [
    "这些方法中的任何一个都将聚合跨多个模型调用的令牌使用情况。例如，您可以在[代理](https://python.langchain.com/docs/concepts/agents/)中使用它来跟踪对一个模型的重复调用的令牌使用情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acbead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe945078-ee2d-43ba-8cdf-afb2f2f4ecef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What's the weather in Boston?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_izMdhUYpp9Vhx7DTNAiybzGa)\n",
      " Call ID: call_izMdhUYpp9Vhx7DTNAiybzGa\n",
      "  Args:\n",
      "    location: Boston\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "It's sunny.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The weather in Boston is sunny.\n",
      "\n",
      "Total usage: {'gpt-4o-mini-2024-07-18': {'input_token_details': {'audio': 0, 'cache_read': 0}, 'input_tokens': 125, 'total_tokens': 149, 'output_tokens': 24, 'output_token_details': {'audio': 0, 'reasoning': 0}}}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "# Create a tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the weather at a location.\"\"\"\n",
    "    return \"It's sunny.\"\n",
    "\n",
    "\n",
    "callback = UsageMetadataCallbackHandler()\n",
    "\n",
    "tools = [get_weather]\n",
    "agent = create_react_agent(\"openai:gpt-4o-mini\", tools)\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Boston?\"}]},\n",
    "    stream_mode=\"values\",\n",
    "    config={\"callbacks\": [callback]},\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "print(f\"\\nTotal usage: {callback.usage_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33172f31",
   "metadata": {},
   "source": [
    "## 下一步\n",
    "\n",
    "您现在已经看到了几个如何跟踪支持的提供商的令牌使用情况的例子。\n",
    "\n",
    "接下来，查看本节中关于聊天模型的其他操作指南，例如[如何让模型返回结构化输出](/docs/how_to/structured_output)或[如何为聊天模型添加缓存](/docs/how_to/chat_model_caching)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40375d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
