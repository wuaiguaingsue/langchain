{
 "cells": [
  {
   "cell_type": "raw",
   "id": "17546ebb",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_position: 4\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c03f40-1328-412d-8a48-1db0cd481b77",
   "metadata": {},
   "source": [
    "# 使用 AgentExecutor 构建代理（旧版）\n",
    "\n",
    ":::important\n",
    "本节将介绍如何使用旧版 LangChain AgentExecutor 构建代理。这些方法适合入门，但在某些情况下，您可能需要它们无法提供的灵活性和控制能力。要使用更高级的代理，我们建议查看 [LangGraph 代理](/docs/concepts/architecture/#langgraph) 或 [迁移指南](/docs/how_to/migrate_agent/)。\n",
    ":::\n",
    "\n",
    "语言模型本身无法执行操作——它们只输出文本。\n",
    "LangChain 的一个重要用例是创建 **[代理](/docs/concepts/agents/)**。\n",
    "代理是使用 LLM 作为推理引擎来确定要采取的操作及其输入的系统。\n",
    "这些操作的结果可以反馈给代理，它会决定是否需要更多操作，或者是否可以结束。\n",
    "\n",
    "在本教程中，我们将构建一个可以与多个不同工具交互的代理：一个是本地数据库，另一个是搜索引擎。您将能够向此代理提问，观察它调用工具，并与之对话。\n",
    "\n",
    "## 概念\n",
    "\n",
    "我们将介绍的概念包括：\n",
    "- 使用 [语言模型](/docs/concepts/chat_models)，特别是它们的工具调用能力\n",
    "- 创建一个 [Retriever](/docs/concepts/retrievers) 来向我们的代理公开特定信息\n",
    "- 使用搜索 [工具](/docs/concepts/tools) 在线查找信息\n",
    "- [`聊天历史`](/docs/concepts/chat_history)，允许聊天机器人“记住”过去的交互并在回答后续问题时考虑它们。\n",
    "- 使用 [LangSmith](https://docs.smith.langchain.com/) 调试和跟踪您的应用程序\n",
    "\n",
    "## 设置\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "本指南（以及文档中的大多数其他指南）使用 [Jupyter notebooks](https://jupyter.org/) 并假设读者也在使用它。Jupyter notebooks 非常适合学习如何使用 LLM 系统，因为很多时候事情可能会出错（意外输出、API 停止工作等），在交互式环境中学习指南是更好地理解它们的好方法。\n",
    "\n",
    "本教程和其他教程可能最方便在 Jupyter notebook 中运行。有关安装说明，请参见[此处](https://jupyter.org/install)。\n",
    "\n",
    "### 安装\n",
    "\n",
    "要安装 LangChain，请运行：\n",
    "\n",
    "import Tabs from '@theme/Tabs';\n",
    "import TabItem from '@theme/TabItem';\n",
    "import CodeBlock from \"@theme/CodeBlock\";\n",
    "\n",
    "<Tabs>\n",
    "  <TabItem value=\"pip\" label=\"Pip\" default>\n",
    "    <CodeBlock language=\"bash\">pip install langchain</CodeBlock>\n",
    "  </TabItem>\n",
    "  <TabItem value=\"conda\" label=\"Conda\">\n",
    "    <CodeBlock language=\"bash\">conda install langchain -c conda-forge</CodeBlock>\n",
    "  </TabItem>\n",
    "</Tabs>\n",
    "\n",
    "\n",
    "\n",
    "有关更多详细信息，请参见我们的[安装指南](/docs/how_to/installation)。\n",
    "\n",
    "### LangSmith\n",
    "\n",
    "您使用 LangChain 构建的许多应用程序将包含多个步骤和多次 LLM 调用。\n",
    "随着这些应用程序变得越来越复杂，能够检查链或代理内部发生的确切情况变得至关重要。\n",
    "最好的方法是使用 [LangSmith](https://smith.langchain.com)。\n",
    "\n",
    "在上面的链接注册后，请确保设置环境变量以开始记录跟踪：\n",
    "\n",
    "```shell\n",
    "export LANGSMITH_TRACING=\"true\"\n",
    "export LANGSMITH_API_KEY=\"...\"\n",
    "```\n",
    "\n",
    "或者，如果在 notebook 中，您可以使用以下方式设置它们：\n",
    "\n",
    "```python\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335d1bf",
   "metadata": {},
   "source": [
    "## 定义工具\n",
    "\n",
    "我们首先需要创建我们想要使用的工具。我们将使用两个工具：[Tavily](/docs/integrations/tools/tavily_search)（用于在线搜索）和一个我们将创建的本地索引的检索器。\n",
    "\n",
    "### [Tavily](/docs/integrations/tools/tavily_search)\n",
    "\n",
    "我们在 LangChain 中有一个内置工具，可以轻松使用 Tavily 搜索引擎作为工具。\n",
    "请注意，这需要一个 API 密钥——他们有一个免费套餐，但如果您没有或不想创建一个，可以忽略此步骤。\n",
    "\n",
    "创建 API 密钥后，您需要将其导出为：\n",
    "\n",
    "```bash\n",
    "export TAVILY_API_KEY=\"...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "482ce13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc86c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e593bbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1714000492, 'localtime': '2024-04-24 16:14'}, 'current': {'last_updated_epoch': 1713999600, 'last_updated': '2024-04-24 16:00', 'temp_c': 15.6, 'temp_f': 60.1, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 10.5, 'wind_kph': 16.9, 'wind_degree': 330, 'wind_dir': 'NNW', 'pressure_mb': 1018.0, 'pressure_in': 30.06, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 72, 'cloud': 100, 'feelslike_c': 15.6, 'feelslike_f': 60.1, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 14.8, 'gust_kph': 23.8}}\"},\n",
       " {'url': 'https://www.weathertab.com/en/c/e/04/united-states/california/san-francisco/',\n",
       "  'content': 'San Francisco Weather Forecast for Apr 2024 - Risk of Rain Graph. Rain Risk Graph: Monthly Overview. Bar heights indicate rain risk percentages. Yellow bars mark low-risk days, while black and grey bars signal higher risks. Grey-yellow bars act as buffers, advising to keep at least one day clear from the riskier grey and black days, guiding ...'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8097977",
   "metadata": {},
   "source": [
    "### 检索器\n",
    "\n",
    "我们还将创建一个检索器，用于我们自己的数据。有关每个步骤的更深入解释，请参见[本教程](/docs/tutorials/rag)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9ce713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ").split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae53ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='# The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \\'langsmith\\';import { runOnDataset } from \\'langchain/smith\\';import { EvaluationResult } from \\'langsmith/evaluation\\';const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {    description: \"A sample dataset in LangSmith.\"});await client.createExamples({    inputs: [        { postfix: \"to LangSmith\" },        { postfix: \"to Evaluations in LangSmith\" },    ],    outputs: [        { output: \"Welcome to LangSmith\" },        { output: \"Welcome to Evaluations in LangSmith\" },    ],    datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async ({ run, example }: { run: Run; example?:', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"how to upload a dataset\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeca39",
   "metadata": {},
   "source": [
    "现在我们已经填充了我们将进行检索的索引，我们可以轻松地将其转换为工具（代理正确使用它所需的格式）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117594b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7280b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b47c1d",
   "metadata": {},
   "source": [
    "### 工具\n",
    "\n",
    "现在我们已经创建了两者，我们可以创建一个工具列表，以便在下游使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8e8e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00068b0",
   "metadata": {},
   "source": [
    "## 使用语言模型\n",
    "\n",
    "接下来，让我们学习如何使用语言模型调用工具。LangChain 支持许多不同的语言模型，您可以互换使用——选择您想要使用的模型！\n",
    "\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs overrideParams={{openai: {model: \"gpt-4\"}}} />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69185491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ed8bf",
   "metadata": {},
   "source": [
    "您可以通过传入消息列表来调用语言模型。默认情况下，响应是一个 `content` 字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c96c960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf8210",
   "metadata": {},
   "source": [
    "我们现在可以看到启用此模型进行工具调用是什么样子。为了启用它，我们使用 `.bind_tools` 为语言模型提供这些工具的知识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba692a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd920b69",
   "metadata": {},
   "source": [
    "我们现在可以调用模型。首先用普通消息调用它，看看它如何响应。我们可以查看 `content` 字段以及 `tool_calls` 字段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a7e925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: Hello! How can I assist you today?\n",
      "ToolCalls: []\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c81e76",
   "metadata": {},
   "source": [
    "现在，让我们尝试用一些输入调用它，这些输入会期望调用工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688b465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentString: \n",
      "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_4HteVahXkRAkWjp6dGXryKZX'}]\n"
     ]
    }
   ],
   "source": [
    "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
    "\n",
    "print(f\"ContentString: {response.content}\")\n",
    "print(f\"ToolCalls: {response.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c4bcd3",
   "metadata": {},
   "source": [
    "我们可以看到现在没有内容，但有一个工具调用！它希望我们调用 Tavily 搜索工具。\n",
    "\n",
    "这还没有调用该工具——它只是告诉我们要调用它。为了实际调用它，我们需要创建我们的代理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ccec80",
   "metadata": {},
   "source": [
    "## 创建代理\n",
    "\n",
    "现在我们已经定义了工具和 LLM，我们可以创建代理。我们将使用一个工具调用代理——有关此类型代理以及其他选项的更多信息，请参见[本指南](/docs/concepts/agents/)。\n",
    "\n",
    "我们可以首先选择我们想要用来指导代理的提示。\n",
    "\n",
    "如果您想查看此提示的内容并访问 LangSmith，您可以访问：\n",
    "\n",
    "[https://smith.langchain.com/hub/hwchase17/openai-functions-agent](https://smith.langchain.com/hub/hwchase17/openai-functions-agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af83d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# 获取要使用的提示 - 您可以修改它！\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8014c9d",
   "metadata": {},
   "source": [
    "现在，我们可以使用 LLM、提示和工具初始化代理。代理负责接收输入并决定采取哪些操作。至关重要的是，代理不会执行这些操作——这是由 AgentExecutor（下一步）完成的。有关如何思考这些组件的更多信息，请参见我们的[概念指南](/docs/concepts/agents)。\n",
    "\n",
    "请注意，我们传入的是 `model`，而不是 `model_with_tools`。这是因为 `create_tool_calling_agent` 会在底层为我们调用 `.bind_tools`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89cf72b4-6046-4b47-8f27-5522d8cb8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "agent = create_tool_calling_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58c9f8",
   "metadata": {},
   "source": [
    "最后，我们将代理（大脑）与工具结合在 AgentExecutor 中（它将重复调用代理并执行工具）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce33904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4df0e06",
   "metadata": {},
   "source": [
    "## 运行代理\n",
    "\n",
    "我们现在可以在一些查询上运行代理！请注意，目前，这些都是**无状态**查询（它不会记住以前的交互）。\n",
    "\n",
    "首先，让我们看看当不需要调用工具时它如何响应："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "114ba50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71493a42",
   "metadata": {},
   "source": [
    "为了确切了解底层发生了什么（并确保它没有调用工具），我们可以查看 [LangSmith 跟踪](https://smith.langchain.com/public/8441812b-94ce-4832-93ec-e1114214553a/r)。\n",
    "\n",
    "现在让我们尝试一个应该调用检索器的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fa4780a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith is a platform that aids in building production-grade Language Learning Model (LLM) applications. It can assist with testing in several ways:\\n\\n1. **Monitoring and Evaluation**: LangSmith allows close monitoring and evaluation of your application. This helps you to ensure the quality of your application and deploy it with confidence.\\n\\n2. **Tracing**: LangSmith has tracing capabilities that can be beneficial for debugging and understanding the behavior of your application.\\n\\n3. **Evaluation Capabilities**: LangSmith has built-in tools for evaluating the performance of your LLM. \\n\\n4. **Prompt Hub**: This is a prompt management tool built into LangSmith that can help in testing different prompts and their responses.\\n\\nPlease note that to use LangSmith, you would need to install it and create an API key. The platform offers Python and Typescript SDKs for utilization. It works independently and does not require the use of LangChain.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d94242",
   "metadata": {},
   "source": [
    "让我们看看 [LangSmith 跟踪](https://smith.langchain.com/public/762153f6-14d4-4c98-8659-82650f860c62/r)，确保它确实在调用它。\n",
    "\n",
    "现在让我们尝试一个需要调用搜索工具的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77c2f769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'The current weather in San Francisco is partly cloudy with a temperature of 16.1°C (61.0°F). The wind is coming from the WNW at a speed of 10.5 mph. The humidity is at 67%. [source](https://www.weatherapi.com/)'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c174f838",
   "metadata": {},
   "source": [
    "我们可以查看 [LangSmith 跟踪](https://smith.langchain.com/public/36df5b1a-9a0b-4185-bae2-964e1d53c665/r)，确保它有效地调用了搜索工具。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cbc8a",
   "metadata": {},
   "source": [
    "## 添加内存\n",
    "\n",
    "如前所述，此代理是无状态的。这意味着它不会记住以前的交互。为了给它内存，我们需要传入以前的 `chat_history`。注意：它需要被称为 `chat_history`，因为我们使用的提示。如果我们使用不同的提示，我们可以更改变量名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4073e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is bob',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里我们传入一个空的消息列表作为 chat_history，因为这是聊天中的第一条消息\n",
    "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dc5ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "550e0c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'input': \"what's my name?\",\n",
       " 'output': 'Your name is Bob. How can I assist you further?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"hi! my name is bob\"),\n",
    "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        ],\n",
    "        \"input\": \"what's my name?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b3bcf2",
   "metadata": {},
   "source": [
    "如果我们想自动跟踪这些消息，我们可以将其包装在 RunnableWithMessageHistory 中。有关如何使用它的更多信息，请参见[本指南](/docs/how_to/message_history)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8edd96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c450d6a5",
   "metadata": {},
   "source": [
    "因为我们有多个输入，我们需要指定两件事：\n",
    "\n",
    "- `input_messages_key`：用于添加到对话历史的输入键。\n",
    "- `history_messages_key`：用于添加加载消息的键。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "828d1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f5932b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"hi! I'm bob\",\n",
       " 'chat_history': [],\n",
       " 'output': 'Hello Bob! How can I assist you today?'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! I'm bob\"},\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae627966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"what's my name?\",\n",
       " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
       " 'output': 'Your name is Bob.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"what's my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2798e",
   "metadata": {},
   "source": [
    "示例 LangSmith 跟踪：https://smith.langchain.com/public/98c8d162-60ae-4493-aa9f-992d87bd0429/r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029798f",
   "metadata": {},
   "source": [
    "## 结论\n",
    "\n",
    "到此为止！在这个快速入门中，我们介绍了如何创建一个简单的代理。代理是一个复杂的主题，还有很多东西需要学习！\n",
    "\n",
    ":::important\n",
    "本节介绍了使用 LangChain 代理进行构建。它们适合入门，但在某些情况下，您可能需要它们无法提供的灵活性和控制能力。要开发更高级的代理，我们建议查看 [LangGraph](/docs/concepts/architecture/#langgraph)。\n",
    ":::\n",
    "\n",
    "如果您想继续使用 LangChain 代理，一些不错的高级指南包括：\n",
    "\n",
    "- [如何使用 LangGraph 的内置版本 `AgentExecutor`](/docs/how_to/migrate_agent)\n",
    "- [如何创建自定义代理](https://python.langchain.com/v0.1/docs/modules/agents/how_to/custom_agent/)\n",
    "- [如何从代理流式传输响应](https://python.langchain.com/v0.1/docs/modules/agents/how_to/streaming/)\n",
    "- [如何从代理返回结构化输出](https://python.langchain.com/v0.1/docs/modules/agents/how_to/agent_structured/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ec3244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
