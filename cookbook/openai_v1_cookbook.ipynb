{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f970f757-ec76-4bf0-90cd-a2fb68b945e3",
   "metadata": {},
   "source": [
    "# 探索 OpenAI V1 功能\n",
    "\n",
    "在 2023 年 11 月 6 日，OpenAI 发布了许多新功能，并将其 Python SDK 版本升级到 1.0.0。本笔记本展示了这些新功能以及如何在 LangChain 中使用它们。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee897729-263a-4073-898f-bb4cf01ed829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要 openai>=1.1.0, langchain>=0.0.335, langchain-experimental>=0.0.39\n",
    "!pip install -U openai langchain langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e067ce-7a43-47a7-bc89-41f1de4cf136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e7e95-90a1-4f73-98fe-10c4b4e0951b",
   "metadata": {},
   "source": [
    "## [视觉功能](https://platform.openai.com/docs/guides/vision)\n",
    "\n",
    "OpenAI 发布了多模态模型，可以接收文本和图像序列作为输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c3965-d3c9-4186-b5f3-5e67855ef916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The image appears to be a diagram representing the architecture or components of a software system or framework related to language processing, possibly named LangChain or associated with a project or product called LangChain, based on the prominent appearance of that term. The diagram is organized into several layers or aspects, each containing various elements or modules:\\n\\n1. **Protocol**: This may be the foundational layer, which includes \"LCEL\" and terms like parallelization, fallbacks, tracing, batching, streaming, async, and composition. These seem related to communication and execution protocols for the system.\\n\\n2. **Integrations Components**: This layer includes \"Model I/O\" with elements such as the model, output parser, prompt, and example selector. It also has a \"Retrieval\" section with a document loader, retriever, embedding model, vector store, and text splitter. Lastly, there\\'s an \"Agent Tooling\" section. These components likely deal with the interaction with external data, models, and tools.\\n\\n3. **Application**: The application layer features \"LangChain\" with chains, agents, agent executors, and common application logic. This suggests that the system uses a modular approach with chains and agents to process language tasks.\\n\\n4. **Deployment**: This contains \"Lang')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=256)\n",
    "chat.invoke(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"这张图片显示了什么\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png\",\n",
    "                        \"detail\": \"auto\",\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f8248-fcf3-4052-a4a3-0684e08f8785",
   "metadata": {},
   "source": [
    "## [OpenAI 助手](https://platform.openai.com/docs/assistants/overview)\n",
    "\n",
    "> Assistants API 允许您在自己的应用程序中构建 AI 助手。助手具有指令，可以利用模型、工具和知识来响应用户查询。Assistants API 目前支持三种类型的工具：代码解释器、检索和函数调用。\n",
    "\n",
    "您可以使用 OpenAI 工具或自定义工具与 OpenAI 助手进行交互。当仅使用 OpenAI 工具时，您可以直接调用助手并获取最终答案。当使用自定义工具时，您可以使用内置的 AgentExecutor 运行助手和工具执行循环，或者轻松编写自己的执行器。\n",
    "\n",
    "下面我们展示与助手交互的不同方式。作为一个简单的示例，让我们构建一个可以编写和运行代码的数学导师。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318da28d-4cec-42ab-ae3e-76d95bb34fa5",
   "metadata": {},
   "source": [
    "### 仅使用 OpenAI 工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9064bbe-d9f7-4a29-a7b3-73933b3197e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.openai_assistant import OpenAIAssistantRunnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a008-49ac-46d2-aa26-b270118af5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThreadMessage(id='msg_g9OJv0rpPgnc3mHmocFv7OVd', assistant_id='asst_hTwZeNMMphxzSOqJ01uBMsJI', content=[MessageContentText(text=Text(annotations=[], value='The result of \\\\(10 - 4^{2.7}\\\\) is approximately \\\\(-32.224\\\\).'), type='text')], created_at=1699460600, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_nBIT7SiAwtUfSCTrQNSPLOfe', thread_id='thread_14n4GgXwxgNL0s30WJW5F6p0')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant\",\n",
    "    instructions=\"你是一个私人数学导师。编写并运行代码以回答数学问题。\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "output = interpreter_assistant.invoke({\"content\": \"10 - 4 的 2.7 次方是多少\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddd181-ac63-4ab6-a40d-a236120379c1",
   "metadata": {},
   "source": [
    "### 作为具有任意工具的 LangChain 代理\n",
    "\n",
    "现在让我们使用我们自己的工具重新创建这个功能。对于这个示例，我们将使用 [E2B 沙箱运行时工具](https://e2b.dev/docs?ref=landing-page-get-started)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cc355-f2d6-4c51-bcf7-f502868357d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install e2b duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48681ac7-b267-48d4-972c-8a7df8393a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun, E2BDataAnalysisTool\n",
    "\n",
    "tools = [E2BDataAnalysisTool(api_key=\"...\"), DuckDuckGoSearchRun()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c01dd79-dd3e-4509-a2e2-009a7f99f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant e2b tool\",\n",
    "    instructions=\"你是一个私人数学导师。编写并运行代码以回答数学问题。你还可以搜索互联网。\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac71d8b-4b4b-4f98-b826-6b3c57a34166",
   "metadata": {},
   "source": [
    "#### 使用 AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f137f94-801f-4766-9ff5-2de9df5e8079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"What's the weather in SF today divided by 2.7\",\n",
       " 'output': \"The weather in San Francisco today is reported to have temperatures as high as 66 °F. To get the temperature divided by 2.7, we will calculate that:\\n\\n66 °F / 2.7 = 24.44 °F\\n\\nSo, when the high temperature of 66 °F is divided by 2.7, the result is approximately 24.44 °F. Please note that this doesn't have a meteorological meaning; it's purely a mathematical operation based on the given temperature.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
    "agent_executor.invoke({\"content\": \"今天旧金山的天气除以 2.7 是多少\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a0b1d-c1b3-4b50-9dce-1189b51a6206",
   "metadata": {},
   "source": [
    "#### 自定义执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0475fa7-b6c1-4331-b8e2-55407466c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantRunnable.create_assistant(\n",
    "    name=\"langchain assistant e2b tool\",\n",
    "    instructions=\"你是一个私人数学导师。编写并运行代码以回答数学问题。\",\n",
    "    tools=tools,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    as_agent=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76cb669-6aba-4827-868f-00aa960026f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "\n",
    "\n",
    "def execute_agent(agent, tools, input):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    response = agent.invoke(input)\n",
    "    while not isinstance(response, AgentFinish):\n",
    "        tool_outputs = []\n",
    "        for action in response:\n",
    "            tool_output = tool_map[action.tool].invoke(action.tool_input)\n",
    "            print(action.tool, action.tool_input, tool_output, end=\"\\n\\n\")\n",
    "            tool_outputs.append(\n",
    "                {\"output\": tool_output, \"tool_call_id\": action.tool_call_id}\n",
    "            )\n",
    "        response = agent.invoke(\n",
    "            {\n",
    "                \"tool_outputs\": tool_outputs,\n",
    "                \"run_id\": action.run_id,\n",
    "                \"thread_id\": action.thread_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946116a-b82f-492e-835e-ca958a8949a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2b_data_analysis {'python_code': 'print(10 - 4 ** 2.7)'} {\"stdout\": \"-32.22425314473263\", \"stderr\": \"\", \"artifacts\": []}\n",
      "\n",
      "\\( 10 - 4^{2.7} \\) is approximately \\(-32.22425314473263\\).\n"
     ]
    }
   ],
   "source": [
    "response = execute_agent(agent, tools, {\"content\": \"10 - 4 的 2.7 次方是多少\"})\n",
    "print(response.return_values[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2744a56-9f4f-4899-827a-fa55821c318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2b_data_analysis {'python_code': 'result = 10 - 4 ** 2.7\\nprint(result + 17.241)'} {\"stdout\": \"-14.983253144732629\", \"stderr\": \"\", \"artifacts\": []}\n",
      "\n",
      "When you add \\( 17.241 \\) to \\( 10 - 4^{2.7} \\), the result is approximately \\( -14.98325314473263 \\).\n"
     ]
    }
   ],
   "source": [
    "next_response = execute_agent(\n",
    "    agent, tools, {\"content\": \"现在加上 17.241\", \"thread_id\": response.thread_id}\n",
    ")\n",
    "print(next_response.return_values[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c34763-d1e7-4b9a-a9d7-3e4cc0dfc2c4",
   "metadata": {},
   "source": [
    "## [JSON 模式](https://platform.openai.com/docs/guides/text-generation/json-mode)\n",
    "\n",
    "限制模型只生成有效的 JSON。注意，您必须包含一个带有使用 JSON 指令的系统消息，才能使此模式工作。\n",
    "\n",
    "仅适用于某些模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6072c4-f3f3-415d-872b-71ea9f3c02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "output = chat.invoke(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"提取以下陈述中提到的任何公司的 'name' 和 'origin'。返回一个 JSON 列表。\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Google 成立于美国，而 Deepmind 成立于英国\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e00ccf-b991-4249-846b-9500a0ccbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a94d9-4319-4ab7-a979-c475ce6b5f50",
   "metadata": {},
   "source": [
    "## [系统指纹](https://platform.openai.com/docs/guides/text-generation/reproducible-outputs)\n",
    "\n",
    "OpenAI 有时会以影响输出的方式更改模型配置。每当这种情况发生时，与生成相关的 system_fingerprint 将会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281883c-bf8f-4665-89cd-4f33ccde69ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "output = chat.generate(\n",
    "    [\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"提取以下陈述中提到的任何公司的 'name' 和 'origin'。返回一个 JSON 列表。\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=\"Google 成立于美国，而 Deepmind 成立于英国\"\n",
    "            ),\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "print(output.llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6565be-985d-4127-848e-c3bca9d7b434",
   "metadata": {},
   "source": [
    "## Azure 类的重大变更\n",
    "\n",
    "OpenAI V1 重写了他们的客户端，并分离了 Azure 和 OpenAI 客户端。这导致在使用 OpenAI V1 时 LangChain 接口发生了一些变化。\n",
    "\n",
    "重大变更：\n",
    "- 要使用带有 OpenAI V1 的 Azure 嵌入，您需要使用新的 `AzureOpenAIEmbeddings` 而不是现有的 `OpenAIEmbeddings`。当使用 `openai<1` 的 Azure 时，`OpenAIEmbeddings` 继续工作。\n",
    "```python\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "```\n",
    "\n",
    "建议的变更：\n",
    "- 当使用 `AzureChatOpenAI` 或 `AzureOpenAI` 时，如果传入 Azure 端点（例如 https://example-resource.azure.openai.com/），应通过 `azure_endpoint` 参数或 `AZURE_OPENAI_ENDPOINT` 指定。我们暂时保持通过 `openai_api_base`/`base_url` 或环境变量 `OPENAI_API_BASE` 指定的向后兼容性，但不应依赖这种方式。\n",
    "- 使用 Azure 聊天或嵌入模型时，通过 `openai_api_key` 参数或 `AZURE_OPENAI_API_KEY` 参数传入 API 密钥。我们暂时保持通过 `OPENAI_API_KEY` 指定的向后兼容性，但不应依赖这种方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49944887-3972-497e-8da2-6d32d44345a9",
   "metadata": {},
   "source": [
    "## 工具\n",
    "\n",
    "使用工具进行并行函数调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916292d8-0f89-40a6-af1c-5a1122327de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GetCurrentWeather(location='New York, NY', unit='fahrenheit'),\n",
       " GetCurrentWeather(location='Los Angeles, CA', unit='fahrenheit'),\n",
       " GetCurrentWeather(location='San Francisco, CA', unit='fahrenheit')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class GetCurrentWeather(BaseModel):\n",
    "    \"\"\"获取某地的当前天气。\"\"\"\n",
    "\n",
    "    location: str = Field(description=\"城市和州，例如 San Francisco, CA\")\n",
    "    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
    "        default=\"fahrenheit\", description=\"温度单位，默认为华氏度\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"你是一个乐于助人的助手\"), (\"user\", \"{input}\")]\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n",
    "    tools=[convert_pydantic_to_openai_tool(GetCurrentWeather)]\n",
    ")\n",
    "chain = prompt | model | PydanticToolsParser(tools=[GetCurrentWeather])\n",
    "\n",
    "chain.invoke({\"input\": \"纽约、洛杉矶和旧金山的天气怎么样\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry-venv",
   "language": "python",
   "name": "poetry-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
